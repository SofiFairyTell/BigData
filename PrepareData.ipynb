{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1794d8-4c76-4325-8ca1-b421da89dbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Загрузите файл data.csv в DataFrame\n",
    "df = pd.read_csv('data.csv', sep=',')\n",
    "# Добавьте столбец \"Дата начала\" с датами большими или равными датам в столбце \"Дата\"\n",
    "start_dates = pd.to_datetime(df['Дата'], format='%d.%m.%Y') + pd.to_timedelta(np.random.randint(0, 5, size=len(df)), unit='D')\n",
    "\n",
    "df['Дата начала'] = start_dates\n",
    "\n",
    "# Создайте массив приоритетов и добавьте столбец \"Приоритет\" с случайными значениями из массива\n",
    "priorities = ['Нормальный', 'Низкий', 'Высокий']\n",
    "df['Приоритет'] = np.random.choice(priorities, size=len(df))\n",
    "\n",
    "# Создайте столбец \"Связанные задачи\" с номерами связанных задач\n",
    "related_tasks = [\"связана с #{}\".format(i) for i in np.random.randint(1, len(df) + 1, size=len(df))]\n",
    "df['Связанные задачи'] = related_tasks\n",
    "\n",
    "# Создайте столбец \"Готовность\" с процентами (20, 50, 70, 100)\n",
    "readiness = np.random.choice([20, 50, 70, 100], size=len(df))\n",
    "df['Готовность'] = readiness\n",
    "\n",
    "# Добавьте случайные пропуски в данные (пустые значения)\n",
    "df.loc[np.random.choice(df.index, size=int(0.1 * len(df)), replace=False), 'Приоритет'] = np.nan\n",
    "df.loc[np.random.choice(df.index, size=int(0.1 * len(df)), replace=False), 'Связанные задачи'] = np.nan\n",
    "df.loc[np.random.choice(df.index, size=int(0.1 * len(df)), replace=False), 'Готовность'] = np.nan\n",
    "\n",
    "# Сохраните обновленный DataFrame обратно в файл data.csv\n",
    "df.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825ce642-45d3-4bb5-9874-81ab8bb76e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Загрузите данные из файла\n",
    "df = pd.read_csv('ourPerson.csv', sep=';')\n",
    "\n",
    "# Генерация случайных значений в диапазоне [1, 4] для столбца \"JobInvolvement\"\n",
    "df['JobInvolvement'] = np.random.randint(1, 5, size=len(df))\n",
    "\n",
    "# Генерация случайных значений в диапазоне [1, 4] для столбца \"PerformanceRating\"\n",
    "df['PerformanceRating'] = np.random.randint(1, 5, size=len(df))\n",
    "\n",
    "# Сохраните обновленные данные в файл\n",
    "df.to_csv('ourPerson.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e8f871-6907-4cc6-b239-5e6ea1fbe348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Загрузить данные из data.csv\n",
    "data_df = pd.read_csv('data.csv')\n",
    "\n",
    "# Извлечь Issue ID из столбца Задача\n",
    "data_df['Issue ID'] = data_df['Задача'].apply(lambda x: re.search(r'#(\\d+)', str(x)).group(1) if re.search(r'#(\\d+)', str(x)) else None)\n",
    "\n",
    "# Преобразовать Issue ID в числовой формат\n",
    "data_df['Issue ID'] = pd.to_numeric(data_df['Issue ID'], errors='coerce')\n",
    "\n",
    "# Загрузить данные из task_info.csv\n",
    "task_info_df = pd.read_csv('tasks_info.csv')\n",
    "\n",
    "# Преобразовать Issue ID в числовой формат\n",
    "task_info_df['Issue ID'] = pd.to_numeric(task_info_df['Issue ID'], errors='coerce')\n",
    "\n",
    "# Объединить данные по полю Issue ID\n",
    "merged_df = pd.merge(data_df, task_info_df[['Issue ID', 'Subtasks ID']], on='Issue ID', how='left')\n",
    "\n",
    "# Порядок столбцов\n",
    "desired_columns_order = [\n",
    "    'Проект', 'Дата', 'Issue ID', 'Задача', 'Subtasks ID', 'Деятельность', 'Направление', 'Дата начала',\n",
    "    'Приоритет', 'Готовность', 'Пользователь', 'EmployeeID', 'Комментарий', 'час(а,ов)', 'Статус',\n",
    "    'Количество дней', 'Плановый срок завершения', 'Дата завершения', 'Дата завершения (отклонение от плана)'\n",
    "]\n",
    "\n",
    "# Упорядочиваем столбцы\n",
    "merged_df = merged_df[desired_columns_order]\n",
    "# Сохранить результат в новый файл data_updated.csv\n",
    "merged_df.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e214eb-6c70-4f33-bf8d-33971a3b7a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузите данные из файла\n",
    "df = pd.read_csv('data.csv', sep=',')\n",
    "\n",
    "# Удалите столбцы JobInvolvement и PerformanceRating\n",
    "df = df.drop(['Связанные задачи'], axis=1)\n",
    "\n",
    "# Сохраните обновленные данные в файл\n",
    "df.to_csv('data.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1376558-3d5e-4ce8-b1a3-73a1b3c8173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузите данные из файла\n",
    "df = pd.read_csv('data.csv', sep=',')\n",
    "\n",
    "# Переставьте столбец Направление рядом со столбцом Задача\n",
    "df = pd.concat([df['Деятельность'], df['Направление'], df.drop(['Деятельность', 'Направление'], axis=1)], axis=1)\n",
    "\n",
    "# Сохраните обновленные данные в файл\n",
    "df.to_csv('data.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c92716-8db8-4e9f-9b55-8e79f658708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузите данные из файла\n",
    "df = pd.read_csv('data.csv', sep=',')\n",
    "\n",
    "# Удалите столбцы JobInvolvement и PerformanceRating\n",
    "df = df.drop(['JobInvolvement', 'PerformanceRating'], axis=1)\n",
    "\n",
    "# Переставьте столбец Направление рядом со столбцом Задача\n",
    "df = pd.concat([df['Задача'], df['Направление'], df.drop(['Задача', 'Направление'], axis=1)], axis=1)\n",
    "\n",
    "# Переставьте столбец EmployeeID рядом со столбцом Пользователь\n",
    "df = pd.concat([df['Пользователь'], df['EmployeeID'], df.drop(['Пользователь', 'EmployeeID'], axis=1)], axis=1)\n",
    "\n",
    "# Сохраните обновленные данные в файл\n",
    "df.to_csv('data.csv', sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637215b4-7e99-47a5-9c70-378a58faa9f0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# Загрузите файл data.csv в DataFrame\n",
    "df = pd.read_csv('data.csv', sep=',')\n",
    "\n",
    "plan_finish_dates = []\n",
    "for index, row in df.iterrows():\n",
    "    # Преобразуйте даты начала и завершения задач в формат \"%d.%m.%Y\"\n",
    "    start_date = datetime.strptime(row['Дата начала'], \"%d.%m.%Y\")\n",
    "    end_date = datetime.strptime(row['Дата'], \"%d.%m.%Y\")\n",
    "    \n",
    "    if end_date < start_date:\n",
    "        end_date, start_date = start_date, end_date  # Поменяем местами даты, если дата завершения раньше даты начала\n",
    "    \n",
    "    # Посчитайте разницу между датами в днях\n",
    "    days_difference = (end_date - start_date).days\n",
    "    \n",
    "    if days_difference == 0:\n",
    "        days_difference = 1  # Если разница в днях равна 0, установим минимальное значение в 1 день\n",
    "    \n",
    "    # Сгенерируйте случайное количество дней в диапазоне от 1 до days_difference\n",
    "    random_days = timedelta(days=random.randint(1, days_difference))\n",
    "    \n",
    "    # Вычислите плановую дату завершения, добавив случайное количество дней к дате начала\n",
    "    plan_finish_date = start_date + random_days\n",
    "    \n",
    "    plan_finish_dates.append(plan_finish_date.strftime(\"%d.%m.%Y\"))\n",
    "\n",
    "# Добавьте столбец \"Плановый срок завершения\" в DataFrame\n",
    "df['Плановый срок завершения'] = plan_finish_dates\n",
    "# Сохраните обновленные данные обратно в CSV-файл\n",
    "df.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb015a6-cc85-441f-953b-9281ce497bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение направления \n",
    "import pandas as pd\n",
    "\n",
    "# Загрузите данные из файла\n",
    "df = pd.read_csv('data.csv', sep=',')\n",
    "\n",
    "# Создайте новый столбец \"Направление\", извлекая информацию до символа #\n",
    "df['Направление'] = df['Задача'].str.split('#').str[0]\n",
    "\n",
    "# Запишите обновленные данные в тот же файл\n",
    "df.to_csv('data.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf91a292-3fa9-4f8b-9fa0-8cad9c12272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Загрузите данные из файла\n",
    "df = pd.read_csv('result.csv', sep=',')\n",
    "\n",
    "# Функция для удаления знаков препинания из текста\n",
    "def remove_punctuation(text):\n",
    "    # Замените знаки препинания на пустую строку\n",
    "    text = re.sub(r'[;,.\\-]', '', text)\n",
    "    return text\n",
    "\n",
    "# Примените функцию к столбцу \"Задача\"\n",
    "df['Задача'] = df['Задача'].apply(remove_punctuation)\n",
    "\n",
    "# Сохраните обновленные данные в тот же файл\n",
    "df.to_csv('result.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c599ce9b-17a6-4ec4-9007-0ad6a9b63ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Загрузите файл data.csv в DataFrame\n",
    "df = pd.read_csv('data.csv', sep=';')\n",
    "\n",
    "# Генерируйте случайные числа от 1 до 30\n",
    "random_days = np.random.randint(1, 31, size=len(df))\n",
    "\n",
    "# Присвойте сгенерированные числа столбцу \"Количество дней\"\n",
    "df['Количество дней'] = random_days\n",
    "\n",
    "# Сохраните обновленный DataFrame обратно в файл data.csv\n",
    "df.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda1b189-5fc4-4a54-a593-fe1b9981b92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Загрузите файл data4_updated.csv в DataFrame\n",
    "df = pd.read_csv('data2.csv', sep=';')\n",
    "\n",
    "# Преобразуйте столбцы \"Плановая дата завершения\" и \"Дата завершения\" в формат даты\n",
    "df['Плановый срок завершения'] = pd.to_datetime(df['Плановый срок завершения'], format='%Y-%m-%d')\n",
    "df['Дата завершения'] = pd.to_datetime(df['Дата завершения'], format='%Y-%m-%d')\n",
    "\n",
    "# Создайте новый столбец \"Дата завершения (отклонение от плана)\" с разницей в днях\n",
    "df['Дата завершения (отклонение от плана)'] = (df['Дата завершения'] - df['Плановый срок завершения']).dt.days\n",
    "\n",
    "# Определите количество строк в DataFrame\n",
    "total_rows = len(df)\n",
    "\n",
    "# Выберите случайные индексы для изменения данных\n",
    "random_indices = random.sample(range(total_rows), int(0.4 * total_rows))\n",
    "\n",
    "# Измените даты в выбранных строках, чтобы они превышали плановые даты завершения\n",
    "for index in random_indices:\n",
    "    # Здесь вы можете создать случайную дату, которая превышает плановую дату завершения\n",
    "    # Например, вы можете добавить случайное количество дней к плановой дате завершения\n",
    "    random_days = random.randint(1, 10)  # Пример: случайно добавить от 1 до 10 дней\n",
    "    new_date = df.at[index, 'Плановый срок завершения'] + pd.Timedelta(days=random_days)\n",
    "    df.at[index, 'Дата завершения'] = new_date\n",
    "\n",
    "# Выберите случайные индексы для строк, которые будут равны плановым датам завершения\n",
    "random_indices = random.sample(range(total_rows), int(0.3 * total_rows))\n",
    "\n",
    "# Измените даты в выбранных строках, чтобы они равнялись плановым датам завершения\n",
    "for index in random_indices:\n",
    "    df.at[index, 'Дата завершения'] = df.at[index, 'Плановый срок завершения']\n",
    "\n",
    "# Сохраните обновленные данные в новый файл\n",
    "df.to_csv('data2.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745f797a-533a-41d1-a32a-c24b97343bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузите файл с данными в DataFrame\n",
    "df = pd.read_csv('data2.csv', sep=';')\n",
    "\n",
    "# Подсчет количества уникальных пользователей\n",
    "unique_users = df['Пользователь'].unique()\n",
    "\n",
    "# Генерация уникальных EmployeeID\n",
    "employee_ids = range(1, 4411)  # Подразумевается, что у вас есть 4410 уникальных пользователей\n",
    "\n",
    "# Создание словаря для соответствия пользователя и EmployeeID\n",
    "user_employee_mapping = dict(zip(unique_users, employee_ids))\n",
    "\n",
    "# Добавление столбца EmployeeID в DataFrame\n",
    "df['EmployeeID'] = df['Пользователь'].map(user_employee_mapping)\n",
    "\n",
    "# Сохраните обновленные данные в новый файл\n",
    "df.to_csv('data2.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332cf9ba-3572-490f-9040-fc560af5c788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузите данные из файлов\n",
    "data_df = pd.read_csv('data2.csv', sep=';')\n",
    "manager_df = pd.read_csv('manager_survey_data.csv')\n",
    "\n",
    "# Объедините данные по столбцу 'EmployeeID'\n",
    "merged_df = data_df.merge(manager_df, on='EmployeeID', how='inner')\n",
    "\n",
    "# Сохраните объединенные данные в новый файл 'ourPerson.csv'\n",
    "merged_df.to_csv('ourPerson.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f516c27-34f0-466c-af83-ed7c8f854910",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 657, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Загрузка данных из файлов\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m timelog_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimelog.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Замените 'timelog.csv' на ваш файл timelog\u001b[39;00m\n\u001b[0;32m      5\u001b[0m tasks_info_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtasks_info.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Замените 'tasks_info.csv' на ваш файл tasks_info\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Извлечение номера задачи из столбца 'Задача' в файле timelog и создание столбца 'Subtask ID'\u001b[39;00m\n",
      "File \u001b[1;32mG:\\Develop\\python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\Develop\\python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\Develop\\python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1748\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1741\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m     (\n\u001b[0;32m   1745\u001b[0m         index,\n\u001b[0;32m   1746\u001b[0m         columns,\n\u001b[0;32m   1747\u001b[0m         col_dict,\n\u001b[1;32m-> 1748\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1749\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1751\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mG:\\Develop\\python312\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:843\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:904\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:879\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:890\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2058\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 657, saw 2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных из файлов\n",
    "timelog_df = pd.read_csv('timelog.csv', sep=';')  # Замените 'timelog.csv' на ваш файл timelog\n",
    "tasks_info_df = pd.read_csv('tasks_info.csv', sep=',')  # Замените 'tasks_info.csv' на ваш файл tasks_info\n",
    "\n",
    "# Извлечение номера задачи из столбца 'Задача' в файле timelog и создание столбца 'Subtask ID'\n",
    "timelog_df['Subtasks ID'] = timelog_df['Задача'].str.extract(r'#(\\d+)')\n",
    "\n",
    "# Обновление значения столбца 'Subtask ID' в timelog на соответствующее из tasks_info, если таковое существует\n",
    "timelog_df['Subtasks ID'] = timelog_df['Subtasks ID'].apply(\n",
    "    lambda x: tasks_info_df.loc[tasks_info_df['Subtasks ID'].astype(str).str.contains(x, na=False), 'Subtasks ID'].values[0] if not tasks_info_df.loc[tasks_info_df['Subtasks ID'].astype(str).str.contains(x, na=False)].empty else x\n",
    ")\n",
    "\n",
    "# Запись результата в новый файл\n",
    "timelog_df.to_csv('timelog.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36b8d2c0-0b77-4733-a63a-79aef5567b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных из файла result.csv\n",
    "result_df = pd.read_csv('timelog.csv', sep=',')  # Замените 'result.csv' на ваш файл result\n",
    "\n",
    "# Извлечение номера задачи из столбца 'Задача' и создание нового столбца 'Номер Задачи'\n",
    "result_df['Номер Задачи'] = result_df['Задача'].str.extract(r'#(\\d+)')\n",
    "\n",
    "# Сохранение обновленного DataFrame в тот же файл\n",
    "result_df.to_csv('timelog.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d28c8997-b33a-4367-a05b-2c55f9a8cd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузите данные из файла\n",
    "df = pd.read_csv('result.csv', sep=',')\n",
    "\n",
    "# Порядок столбцов\n",
    "desired_columns_order = [\n",
    "    'Проект', 'Дата', 'Номер Задачи', 'Задача', 'Subtasks ID', 'Деятельность', 'Направление', \n",
    "    'Пользователь','Комментарий', 'час(а,ов)', 'Статус',\n",
    "    'Количество дней'\n",
    "]\n",
    "\n",
    "# Упорядочиваем столбцы\n",
    "df = df[desired_columns_order]\n",
    "\n",
    "# Сохраните обновленные данные в файл\n",
    "df.to_csv('result.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da8afde3-ce77-4235-9e6b-e78eea677508",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Загрузка данных из файла dataupd.csv\n",
    "dataupd_df = pd.read_csv('dataupd.csv',sep=',')  # Замените 'dataupd.csv' на ваш файл dataupd\n",
    "\n",
    "# Загрузка данных из файла result.csv\n",
    "result_df = pd.read_csv('timelog.csv', sep=',')  # Замените 'result.csv' на ваш файл result\n",
    "\n",
    "# Создание столбцов 'Приоритет' и 'Готовность' в файле result.csv\n",
    "result_df['Приоритет'] = result_df['Номер Задачи'].apply(lambda x: dataupd_df.loc[dataupd_df['Issue ID'] == x, 'Приоритет'].values[0] if x in dataupd_df['Issue ID'].values else None)\n",
    "result_df['Готовность'] = result_df['Номер Задачи'].apply(lambda x: dataupd_df.loc[dataupd_df['Issue ID'] == x, 'Готовность'].values[0] if x in dataupd_df['Issue ID'].values else None)\n",
    "\n",
    "\n",
    "# Удаление дополнительного столбца 'Issue ID'\n",
    "result_df.drop('Номер Задачи', axis=1, inplace=True)\n",
    "\n",
    "# Сохранение обновленного DataFrame в тот же файл\n",
    "result_df.to_csv('timelog.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd1fce7e-7f00-4fd3-bd92-3fd7505fecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных из файла result.csv\n",
    "result_df = pd.read_csv('timelog.csv', sep=',')  # Замените 'result.csv' на ваш файл result\n",
    "\n",
    "# Извлечение номера задачи из столбца 'Задача' и создание нового столбца 'Номер Задачи'\n",
    "result_df['Номер Задачи'] = result_df['Задача'].str.extract(r'#(\\d+)')\n",
    "\n",
    "# Сохранение обновленного DataFrame в тот же файл\n",
    "result_df.to_csv('timelog.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8204b021-cd58-48cd-82aa-73fd0ddf5b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных из файла timelog.csv (замените 'timelog.csv' на фактический путь к вашему файлу)\n",
    "timelog_df = pd.read_csv('timelog.csv', sep=',')\n",
    "\n",
    "# Функция для извлечения кода направления\n",
    "def extract_direction_code(direction):\n",
    "    if pd.notna(direction):\n",
    "        parts = direction.split('-')\n",
    "        if len(parts) > 1 and len(parts[1]) == 2 and parts[1].isupper():\n",
    "            return parts[0] + '-' + parts[1]\n",
    "        else:\n",
    "            return parts[0]\n",
    "    return None\n",
    "\n",
    "# Создание нового столбца 'Код Направления'\n",
    "timelog_df['Код Направления'] = timelog_df['Направление'].apply(extract_direction_code)\n",
    "\n",
    "# Сохранение обновленного DataFrame в тот же файл\n",
    "timelog_df.to_csv('timelog.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dd99e30-bf81-4591-9aa8-bbcfbffa9886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузите данные из файла\n",
    "df = pd.read_csv('timelog.csv', sep=',')\n",
    "\n",
    "# Создайте новый столбец \"Поддеятельность\", извлекая информацию до символа #\n",
    "df['Поддеятельность'] = df['Задача'].str.split('#').str[0]\n",
    "\n",
    "# Удалите столбцы JobInvolvement и PerformanceRating\n",
    "df = df.drop(['Поддеятельность'], axis=1)\n",
    "\n",
    "# Запишите обновленные данные в тот же файл\n",
    "df.to_csv('timelog.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762f25a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
